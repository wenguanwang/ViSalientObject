Keras Implementation (v1) for



Video salient object detection via fully convolutional networks,
IEEE Trans. on Image Processing, 27(1):38-49, 2018



By [Wenguan Wang](https://sites.google.com/site/wenguanwangwwg/) and Jianbing Shen and Ling Shao



========================================================================



Please install keras first

The model weights and results on DAVIS and FBMS datasets can be downloaded
 from 



Baidu Wangpan:https://pan.baidu.com/s/1dE22MFR 


password: jmph  



or from google drive:
https://drive.google.com/drive/u/0/folders/1mc6nnr8RrMZwAXjV0XS9Hv7QJE4quvkx



Please put the models under the folder 'videosalientobjectdetection' and run main.py.



Our results (MAE) are sightly improved over the original scores reported in our paper:

DAVIS: 0.0587
FBMS:  0.0619


You can find our results on UVSD dataset here: https://pan.baidu.com/s/1DUWHiIf-EGG1l-izaAf09Q
========================================================================


Our code for synthesizing video data from still image has been uploaded.

UnZip synthesizevideo.rar first.



Then install vlfeat toolbox first (in 'functions' folder). 



Run synthesizevideo.m.



========================================================================



If you find our method useful in your research,
 please consider citing the following papers:



1) W. Wang, J. Shen, and L. Shao, 
Video salient object detection via fully convolutional networks,
 IEEE Trans. on Image Processing, 27(1):38-49, 2018



2) W. Wang, J. Shen, and L. Shao,
Consistent video saliency using local gradient flow optimization and global refinement,
IEEE Trans. on Image Processing, 24(11):4185-4196, 2015



3) W. Wang, J. Shen, R. Yang, and F. Porikli, Saliency-aware video object segmentation,
IEEE Trans. on Pattern Analysis and Machine Intelligence, 40(1):20-33, 2018



4) W. Wang, J. Shen, F. Porikli, Saliency-aware geodesic video object segmentation,
IEEE CVPR, pp. 3395-3402, 2015



========================================================================



Any comments, please email:
wenguanwang.china@gmail.com
